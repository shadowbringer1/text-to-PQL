{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.84.0-py3-none-any.whl (725 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725 kB 682 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73 kB 139 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 444 kB 155 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.11 in /Users/suchang/Library/Python/3.9/lib/python/site-packages (from openai) (4.14.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78 kB 503 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100 kB 540 kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.10.0-cp39-cp39-macosx_11_0_arm64.whl (312 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312 kB 428 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna>=2.8\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70 kB 530 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /Users/suchang/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78 kB 389 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159 kB 228 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9 MB 196 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sniffio, idna, h11, certifi, typing-inspection, pydantic-core, httpcore, anyio, annotated-types, tqdm, pydantic, jiter, httpx, distro, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 certifi-2025.4.26 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 openai-1.84.0 pydantic-2.11.5 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šsoftware_PSI\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 11 æ¡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "âœ… åœºæ™¯ software_PSI å…±ä¿ç•™ 91 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šsoftware_MPC\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 11 æ¡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "âœ… åœºæ™¯ software_MPC å…±ä¿ç•™ 91 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šsoftware_PIR\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "software_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "âœ… åœºæ™¯ software_PIR å…±ä¿ç•™ 100 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šhardware_PSI\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "[è­¦å‘Š] hardware_PSI åœºæ™¯ JSON è§£æå¤±è´¥ï¼Œå·²ä¿å­˜åŸå§‹æ–‡æœ¬ä¾›æ‰‹åŠ¨å¤„ç†ã€‚\n",
      "  âš ï¸ ç¬¬ 1 æ¬¡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "[è­¦å‘Š] hardware_PSI åœºæ™¯ JSON è§£æå¤±è´¥ï¼Œå·²ä¿å­˜åŸå§‹æ–‡æœ¬ä¾›æ‰‹åŠ¨å¤„ç†ã€‚\n",
      "  âš ï¸ ç¬¬ 3 æ¬¡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PSI åœºæ™¯æˆåŠŸç”Ÿæˆ 15 æ¡ã€‚\n",
      "âœ… åœºæ™¯ hardware_PSI å…±ä¿ç•™ 55 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šhardware_MPC\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 9 æ¡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 11 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 10 æ¡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "[è­¦å‘Š] hardware_MPC åœºæ™¯ JSON è§£æå¤±è´¥ï¼Œå·²ä¿å­˜åŸå§‹æ–‡æœ¬ä¾›æ‰‹åŠ¨å¤„ç†ã€‚\n",
      "  âš ï¸ ç¬¬ 4 æ¬¡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_MPC åœºæ™¯æˆåŠŸç”Ÿæˆ 12 æ¡ã€‚\n",
      "âœ… åœºæ™¯ hardware_MPC å…±ä¿ç•™ 42 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šhardware_PIR\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "[è­¦å‘Š] hardware_PIR åœºæ™¯ JSON è§£æå¤±è´¥ï¼Œå·²ä¿å­˜åŸå§‹æ–‡æœ¬ä¾›æ‰‹åŠ¨å¤„ç†ã€‚\n",
      "  âš ï¸ ç¬¬ 1 æ¬¡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIR åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "âœ… åœºæ™¯ hardware_PIR å…±ä¿ç•™ 80 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šhardware_PIRMPC\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIRMPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIRMPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIRMPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIRMPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "hardware_PIRMPC åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "âœ… åœºæ™¯ hardware_PIRMPC å…±ä¿ç•™ 100 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "ğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼šFederated_learning\n",
      "  â³ ç¬¬ 1/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "Federated_learning åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 2/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "Federated_learning åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 3/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "Federated_learning åœºæ™¯æˆåŠŸç”Ÿæˆ 20 æ¡ã€‚\n",
      "  â³ ç¬¬ 4/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "Federated_learning åœºæ™¯æˆåŠŸç”Ÿæˆ 15 æ¡ã€‚\n",
      "  â³ ç¬¬ 5/5 æ¬¡ç”Ÿæˆä¸­...\n",
      "[è­¦å‘Š] Federated_learning åœºæ™¯ JSON è§£æå¤±è´¥ï¼Œå·²ä¿å­˜åŸå§‹æ–‡æœ¬ä¾›æ‰‹åŠ¨å¤„ç†ã€‚\n",
      "  âš ï¸ ç¬¬ 5 æ¬¡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚\n",
      "âœ… åœºæ™¯ Federated_learning å…±ä¿ç•™ 75 æ¡å»é‡åæ ·æœ¬ã€‚\n",
      "\n",
      "âœ… å…¨éƒ¨ç”Ÿæˆå®Œæˆï¼Œå·²ä¿å­˜è‡³ pql_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-bCeqVHwJt0yXU5VIarZPidGnjGK510UKA19Dqh6EuASQrCEG\",\n",
    "    base_url=\"https://lonlie.plus7.plus/v1\"\n",
    ")\n",
    "\n",
    "scene_name_map = {\n",
    "    \"software_PSI\": \"è½¯ä»¶PSI\",\n",
    "    \"software_MPC\": \"è½¯ä»¶MPC\",\n",
    "    \"software_PIR\": \"è½¯ä»¶PIR\",\n",
    "    \"hardware_PSI\": \"ç¡¬ä»¶PSI\",\n",
    "    \"hardware_MPC\": \"ç¡¬ä»¶MPC\",\n",
    "    \"hardware_PIR\": \"ç¡¬ä»¶PIR\",\n",
    "    \"hardware_PIRMPC\": \"ç¡¬ä»¶PIRMPC\",\n",
    "    \"Federated_learning\": \"è”é‚¦å­¦ä¹ \"\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def build_prompt(rule, num_samples=100, previous_first_sample=None):\n",
    "    prompt = f\"\"\"\n",
    "You are a PQL generation assistant. Your task is to generate exactly {num_samples} high-quality question-PQL triples, formatted as a **raw JSON array** (no markdown or explanatory text), like this:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"question\": \"...\",\n",
    "    \"Chinese_question\": \"...\",\n",
    "    \"PQL_query\": \"...\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "## Generation Requirements:\n",
    "1. Each triple must describe a meaningful secure computation task.\n",
    "2. All table names, field names, and tenant/platform names used in the PQL must appear **explicitly** in both the English and Chinese questions.\n",
    "3. English and Chinese questions must be **natural and fluent**, with **non-templated** phrasing. The Chinese question should NOT be a direct translation.\n",
    "4. Ensure **diversity** in question intent and structure â€” avoid duplicate or near-duplicate questions.\n",
    "5. If the scenario is a hardware environment (such as TEE), please specify it in the question.\n",
    "6. **Only return the JSON array.** Do not include any explanations, headings, markdown (such as ```), or extra text.\n",
    "\"\"\"\n",
    "    if previous_first_sample:\n",
    "        prompt += f\"\"\"\n",
    "\n",
    "## Constraint:\n",
    "Avoid generating samples that are similar in content, structure, or intent to the following existing one:\n",
    "\n",
    "{json.dumps(previous_first_sample, ensure_ascii=False, indent=2)}\n",
    "\"\"\"\n",
    "    prompt += f\"\"\"\n",
    "\n",
    "Based on the rule below, generate {num_samples} diverse and correct samples.\n",
    "\n",
    "Rule:\n",
    "{rule}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_100_triplets(rule, scene, num_samples=100, previous_first_sample=None):\n",
    "    prompt_system = \"You are a database expert proficient in SQL and PQL for privacy-preserving applications.\"\n",
    "    user_prompt = build_prompt(rule, num_samples=num_samples, previous_first_sample=previous_first_sample)\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt_system},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=1.0,\n",
    "            max_tokens=8192\n",
    "        )\n",
    "        content = completion.choices[0].message.content\n",
    "        content = unicodedata.normalize('NFKC', content)\n",
    "\n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "            if isinstance(parsed, list):\n",
    "                print(f\"{scene} åœºæ™¯æˆåŠŸç”Ÿæˆ {len(parsed)} æ¡ã€‚\")\n",
    "                return parsed\n",
    "            else:\n",
    "                raise ValueError(\"è¿”å›å†…å®¹ä¸æ˜¯ JSON æ•°ç»„\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"[è­¦å‘Š] {scene} åœºæ™¯ JSON è§£æå¤±è´¥ï¼Œå·²ä¿å­˜åŸå§‹æ–‡æœ¬ä¾›æ‰‹åŠ¨å¤„ç†ã€‚\")\n",
    "            os.makedirs(\"fallback\", exist_ok=True)\n",
    "            with open(f\"fallback/{scene}_raw.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"[é”™è¯¯] {scene} åœºæ™¯ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    rule_file = \"rules.json\"            # è¾“å…¥è§„åˆ™æ–‡ä»¶ï¼Œæ ¼å¼ï¼š{ \"åœºæ™¯å\": \"è§„åˆ™å†…å®¹\", ... }\n",
    "    output_file = \"pql_dataset.json\"    # æœ€ç»ˆè¾“å‡ºæ–‡ä»¶\n",
    "\n",
    "    with open(rule_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        rules_dict = json.load(f)\n",
    "\n",
    "    final_data = {}\n",
    "\n",
    "    for scene, rule in rules_dict.items():\n",
    "        print(f\"\\nğŸ¯ æ­£åœ¨ç”Ÿæˆåœºæ™¯ï¼š{scene}\")\n",
    "        all_triplets = []\n",
    "        prev_first_sample = None\n",
    "\n",
    "        for i in range(5):\n",
    "            print(f\"  â³ ç¬¬ {i + 1}/5 æ¬¡ç”Ÿæˆä¸­...\")\n",
    "            triplets = generate_100_triplets(rule, scene, num_samples=20, previous_first_sample=prev_first_sample)\n",
    "            if triplets:\n",
    "                all_triplets.extend(triplets)\n",
    "                prev_first_sample = triplets[0]\n",
    "            else:\n",
    "                print(f\"  âš ï¸ ç¬¬ {i + 1} æ¬¡ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        # å»é‡ï¼ˆä»¥ question ä¸ºä¸»ï¼‰\n",
    "        unique_triplets = {}\n",
    "        for item in all_triplets:\n",
    "            q = item[\"question\"]\n",
    "            if q not in unique_triplets:\n",
    "                unique_triplets[q] = item\n",
    "        deduped = list(unique_triplets.values())[:100]\n",
    "\n",
    "        final_data[scene] = deduped\n",
    "        print(f\"âœ… åœºæ™¯ {scene} å…±ä¿ç•™ {len(deduped)} æ¡å»é‡åæ ·æœ¬ã€‚\")\n",
    "\n",
    "    # ä¿å­˜æœ€ç»ˆæ•°æ®é›†\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nâœ… å…¨éƒ¨ç”Ÿæˆå®Œæˆï¼Œå·²ä¿å­˜è‡³ {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
